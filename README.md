# Sistema de AnÃ¡lisis de Sentimientos AcadÃ©mico

Un sistema acadÃ©mico para anÃ¡lisis de sentimientos en textos cortos (â‰¤50 palabras) basado en Ã¡rboles de decisiÃ³n, lÃ³gica proposicional y lÃ³gica difusa, sin usar librerÃ­as de IA.

## ğŸ¯ CaracterÃ­sticas

- **AnÃ¡lisis de 6 sentimientos**: AlegrÃ­a, Tristeza, Enojo, PreocupaciÃ³n, InformaciÃ³n, Sorpresa
- **Arquitectura modular**: Componentes independientes y reutilizables
- **LÃ³gica difusa**: Manejo de intensificadores, atenuadores y negaciones
- **Ãrbol de decisiÃ³n**: BÃºsqueda eficiente con memoizaciÃ³n
- **ValidaciÃ³n robusta**: Manejo de errores y validaciones de entrada
- **Pruebas completas**: Cobertura de pruebas unitarias e integraciÃ³n
- **ConfiguraciÃ³n flexible**: ParÃ¡metros ajustables por archivo JSON

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                    # MÃ³dulos principales
â”‚   â”‚   â”œâ”€â”€ text_preprocessor.py # Preprocesamiento de texto
â”‚   â”‚   â”œâ”€â”€ tree_searcher.py     # BÃºsqueda en Ã¡rbol de decisiÃ³n
â”‚   â”‚   â””â”€â”€ fuzzy_logic.py       # LÃ³gica difusa
â”‚   â”œâ”€â”€ models/                  # Modelos de datos
â”‚   â”‚   â”œâ”€â”€ sentiment_result.py  # Estructuras de resultados
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py # Analizador principal
â”‚   â”‚   â””â”€â”€ exceptions.py        # Excepciones personalizadas
â”‚   â””â”€â”€ utils/                   # Utilidades
â”‚       â”œâ”€â”€ keyword_matcher.py   # Coincidencia de palabras clave
â”‚       â””â”€â”€ normalizer.py        # NormalizaciÃ³n de puntuaciones
â”œâ”€â”€ tests/                       # Pruebas unitarias e integraciÃ³n
â”œâ”€â”€ docs/                        # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ resources/                   # Archivos de configuraciÃ³n y datos
â”œâ”€â”€ main.py                      # Punto de entrada principal
â”œâ”€â”€ requirements.txt             # Dependencias
â””â”€â”€ README.md                    # Este archivo
```

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio**:

```bash
git clone <url-del-repositorio>
cd sistema-analisis-sentimientos
```

2. **Crear entorno virtual**:

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**:

```bash
pip install -r requirements.txt
```

4. **Configurar recursos**:

```bash
mkdir -p resources
# Copiar archivos de configuraciÃ³n y datos a resources/
```

## ğŸ“– Uso

### Uso BÃ¡sico

```python
from src.models.sentiment_analyzer import SentimentAnalyzer
from src.models.sentiment_result import SystemConfig

# Crear configuraciÃ³n
config = SystemConfig()

# Inicializar analizador
analyzer = SentimentAnalyzer(config)

# Analizar texto
result = analyzer.analyze("Â¡Estoy muy feliz hoy!")

# Ver resultados
print(f"Sentimiento dominante: {result.dominant_sentiment}")
print(f"Confianza: {result.confidence:.3f}")
print(f"Puntuaciones: {result.sentiments}")
```

### Uso desde LÃ­nea de Comandos

```bash
# AnÃ¡lisis de texto Ãºnico
python main.py "Estoy muy feliz hoy"

# Modo interactivo
python main.py --interactive

# AnÃ¡lisis desde archivo
python main.py --file textos.txt

# Con configuraciÃ³n personalizada
python main.py --config mi_config.json --verbose

# Mostrar informaciÃ³n del sistema
python main.py --info
```

### AnÃ¡lisis en Lote

```python
texts = [
    "Estoy muy feliz",
    "Me siento triste",
    "Estoy enojado",
    "Estoy preocupado"
]

results = analyzer.batch_analyze(texts)

for i, result in enumerate(results):
    print(f"Texto {i+1}: {result.dominant_sentiment}")
```

## âš™ï¸ ConfiguraciÃ³n

El sistema se configura mediante archivos JSON:

### ConfiguraciÃ³n del Sistema (`resources/system_config.json`)

```json
{
  "max_text_length": 50,
  "min_confidence": 0.3,
  "enable_fuzzy_logic": true,
  "enable_memoization": true,
  "preprocessing": {
    "convert_to_lowercase": true,
    "remove_punctuation": true,
    "max_word_length": 20
  },
  "fuzzy_parameters": {
    "intensification_factor": 1.5,
    "attenuation_factor": 0.7,
    "mixed_emotion_threshold": 0.6
  },
  "tree_search": {
    "max_depth": 10,
    "timeout_seconds": 5,
    "cache_size": 1000
  }
}
```

### Ãrbol de DecisiÃ³n (`resources/decision_tree_structure.json`)

```json
{
  "root": {
    "condition": "has_keyword('alegria', 'feliz')",
    "branches": {
      "true": "node_1",
      "false": "node_2"
    },
    "sentiment_scores": {
      "alegria": 0.5,
      "tristeza": 0.1,
      "enojo": 0.0,
      "preocupacion": 0.0,
      "informacion": 0.2,
      "sorpresa": 0.2
    }
  }
}
```

### Palabras Clave (`resources/sentiment_keywords.json`)

```json
{
  "alegria": {
    "keywords": ["feliz", "contento", "alegre"],
    "synonyms": [["gozoso", "radiante", "eufÃ³rico"]],
    "verb_forms": [["alegrarse", "regocijarse"]]
  }
}
```

## ğŸ§ª Pruebas

### Ejecutar Todas las Pruebas

```bash
pytest tests/ -v
```

### Ejecutar Pruebas con Cobertura

```bash
pytest tests/ --cov=src --cov-report=html
```

### Ejecutar Pruebas EspecÃ­ficas

```bash
# Solo pruebas unitarias
pytest tests/test_text_preprocessor.py -v

# Solo pruebas de integraciÃ³n
pytest tests/test_integration.py -v

# Pruebas con marcadores especÃ­ficos
pytest -m "not slow" -v
```

### Tipos de Pruebas

- **Pruebas Unitarias**: Cada mÃ³dulo individual
- **Pruebas de IntegraciÃ³n**: Sistema completo
- **Pruebas de Rendimiento**: Tiempo de respuesta
- **Pruebas de ValidaciÃ³n**: Casos lÃ­mite y errores

## ğŸ“Š Resultados del AnÃ¡lisis

El sistema devuelve un objeto `SentimentResult` con:

```python
@dataclass
class SentimentResult:
    text: str                           # Texto original
    sentiments: Dict[str, float]        # Puntuaciones por sentimiento
    confidence: float                   # Confianza del anÃ¡lisis (0-1)
    processing_time: float              # Tiempo de procesamiento
    matched_keywords: Dict[str, List[str]] # Palabras clave encontradas
    tree_path: List[str]                # Ruta en el Ã¡rbol de decisiÃ³n
    modifiers_applied: Dict[str, List[str]] # Modificadores aplicados
    dominant_sentiment: Optional[str]   # Sentimiento dominante
    secondary_sentiments: List[str]     # Sentimientos secundarios
    analysis_quality: str               # Calidad del anÃ¡lisis
```

### Ejemplo de Salida

```
Texto: Â¡Estoy muy feliz hoy!
Sentimiento dominante: alegria
Confianza: 0.850
Tiempo de procesamiento: 0.023s
Calidad del anÃ¡lisis: high

Puntuaciones por sentimiento:
  alegria: 0.850
  tristeza: 0.050
  enojo: 0.000
  preocupacion: 0.000
  informacion: 0.050
  sorpresa: 0.050

Palabras clave encontradas:
  alegria: ['feliz']
  tristeza: []
  enojo: []

Ruta en el Ã¡rbol: root -> node_1 -> leaf_1

Modificadores aplicados:
  intensifiers: ['muy']
  negations: []
  attenuators: []
```

## ğŸ”§ Arquitectura

### Flujo de Procesamiento

1. **Preprocesamiento**: Limpieza y extracciÃ³n de modificadores
2. **Coincidencia**: BÃºsqueda de palabras clave por sentimiento
3. **Ãrbol de DecisiÃ³n**: BÃºsqueda para puntuaciones base
4. **LÃ³gica Difusa**: AplicaciÃ³n de modificadores
5. **NormalizaciÃ³n**: Ajuste de puntuaciones al rango [0,1]
6. **Resultado**: GeneraciÃ³n del objeto de resultado

### MÃ³dulos Principales

- **TextPreprocessor**: Limpieza, tokenizaciÃ³n, extracciÃ³n de modificadores
- **KeywordMatcher**: Coincidencia de palabras clave y sinÃ³nimos
- **TreeSearcher**: BÃºsqueda eficiente en Ã¡rbol de decisiÃ³n
- **FuzzyLogicProcessor**: AplicaciÃ³n de reglas de lÃ³gica difusa
- **ScoreNormalizer**: NormalizaciÃ³n y cÃ¡lculo de confianza
- **SentimentAnalyzer**: Orquestador principal del sistema

## ğŸ›ï¸ ConfiguraciÃ³n Avanzada

### ParÃ¡metros de LÃ³gica Difusa

```python
config.fuzzy_parameters = {
    'intensification_factor': 1.5,    # Factor de intensificaciÃ³n
    'attenuation_factor': 0.7,        # Factor de atenuaciÃ³n
    'mixed_emotion_threshold': 0.6,   # Umbral para emociones mixtas
    'context_weight': 0.3             # Peso del contexto
}
```

### ParÃ¡metros de BÃºsqueda en Ãrbol

```python
config.tree_search = {
    'max_depth': 10,                  # Profundidad mÃ¡xima
    'timeout_seconds': 5,             # Timeout de bÃºsqueda
    'cache_size': 1000,               # TamaÃ±o del cache
    'enable_backtracking': True       # Habilitar backtracking
}
```

### ParÃ¡metros de Preprocesamiento

```python
config.preprocessing = {
    'convert_to_lowercase': True,     # Convertir a minÃºsculas
    'remove_punctuation': True,       # Remover puntuaciÃ³n
    'max_word_length': 20,            # Longitud mÃ¡xima de palabra
    'remove_stopwords': False         # Remover palabras vacÃ­as
}
```

## ğŸ“ˆ Rendimiento

### MÃ©tricas TÃ­picas

- **Tiempo de procesamiento**: < 50ms por texto
- **PrecisiÃ³n**: > 80% en textos claros
- **Cobertura**: 6 sentimientos principales
- **Escalabilidad**: Procesamiento en lote eficiente

### Optimizaciones

- **MemoizaciÃ³n**: Cache de resultados de bÃºsqueda
- **BÃºsqueda eficiente**: Algoritmos optimizados en Ã¡rbol
- **Procesamiento paralelo**: AnÃ¡lisis en lote
- **ValidaciÃ³n temprana**: Rechazo de entradas invÃ¡lidas

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes

1. **Archivo de configuraciÃ³n no encontrado**:

   ```bash
   # Verificar que existe resources/system_config.json
   ls resources/
   ```
2. **Error de importaciÃ³n**:

   ```bash
   # Verificar que el entorno virtual estÃ¡ activado
   source venv/bin/activate
   ```
3. **Pruebas fallando**:

   ```bash
   # Ejecutar con mÃ¡s verbosidad
   pytest tests/ -v -s
   ```

### Logs y Debugging

```python
import logging

# Configurar logging detallado
logging.basicConfig(level=logging.DEBUG)

# El analizador generarÃ¡ logs detallados
analyzer = SentimentAnalyzer(config)
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama para feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

### EstÃ¡ndares de CÃ³digo

- **Formato**: Black
- **Linting**: Flake8
- **Tipos**: MyPy
- **Pruebas**: pytest con cobertura > 90%

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Manuel Guarniz**

## ğŸ™ Agradecimientos

- Universidad TecnolÃ³gica del PerÃº
- Departamento de MatemÃ¡tica Discreta
- Profesores y compaÃ±eros del curso

## ğŸ“ Contacto

Para preguntas o soporte:

- Email: cruzemg95@gmail.com
- GitHub Issues: https://github.com/manuelguarniz/project-nlp-simplified/issues

---

**Nota**: Este es un sistema acadÃ©mico diseÃ±ado para fines educativos. Para uso en producciÃ³n, se recomienda realizar validaciones adicionales y ajustes de configuraciÃ³n segÃºn el dominio especÃ­fico.
